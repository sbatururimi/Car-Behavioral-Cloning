{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Conv2D, Cropping2D\n",
    "# from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/virt/anaconda3/envs/autonomous-car/lib/python3.5/site-packages/ipykernel_launcher.py:5: UserWarning: No GPU found. You can drastically improve your network training by using a GPU.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. You can drastically improve your network training by using a GPU.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lines =[]\n",
    "# with open(\"../data-car-behavioral/driving_log.csv\") as csvfile:\n",
    "#     reader = csv.reader(csvfile)\n",
    "#     for line in reader:\n",
    "#     \tlines.append(line)\n",
    "\n",
    "# images = []\n",
    "# measurements = []\n",
    "# for line in lines:\n",
    "# \tsource_path = line[0]\n",
    "# \tfilename = source_path.split('/')[-1]\n",
    "# \tcurrent_path = '../data-car-behavioral/IMG/' + filename\n",
    "# \timage = cv2.imread(current_path)\n",
    "# \timages.append(image)\n",
    "# \t# fleeping images & steering measurements\n",
    "# \tmeasurement = float(line[3])\n",
    "# \tmeasurements.append(measurement)\n",
    "\n",
    "# X_train = np.array(images)\n",
    "# y_train = np.array(measurements)\n",
    "\n",
    "# images = []\n",
    "# measurements = []\n",
    "# for line in lines:\n",
    "# \tsource_path = line[0]\n",
    "# \tfilename = source_path.split('/')[-1]\n",
    "# \tcurrent_path = '../data-car-behavioral/IMG/' + filename\n",
    "# \timage = cv2.imread(current_path)\n",
    "# \timages.append(image)\n",
    "# \t# fleeping images & steering measurements\n",
    "# \tmeasurement = float(line[3])\n",
    "# \tmeasurements.append(measurement)\n",
    "\n",
    "# # data augmentation\n",
    "# augmented_images, augmented_measurements = [], []\n",
    "# for image, measurement in zip(images, measurements):\n",
    "# \taugmented_images.append(image)\n",
    "# \taugmented_measurements.append(measurement)\n",
    "\n",
    "# \taugmented_images.append(cv2.flip(image, 1))\n",
    "# \taugmented_measurements.append(measurement * -1.0)\n",
    "\n",
    "# X_train = np.array(augmented_images)\n",
    "# y_train = np.array(augmented_measurements)\n",
    "\n",
    "car_images = []\n",
    "steering_angles = []\n",
    "with open(\"../data-car-behavioral/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        # lines.append(line)\n",
    "        steering_center = float(line[3])\n",
    "\n",
    "        # create adjusted steering measurements for the side camera images\n",
    "        correction = steering_center * 0.1 # 10%\n",
    "        steering_left = steering_center + correction\n",
    "        steering_right = steering_center - correction\n",
    "\n",
    "        # read in images from center, left and right cameras\n",
    "        for i in range(3):\n",
    "            source_path = line[i]\n",
    "            filename = source_path.split('/')[-1]\n",
    "            current_path = '../data-car-behavioral/IMG/' + filename\n",
    "            image = cv2.imread(current_path)\n",
    "            # add images to data set\n",
    "            car_images.append(image)\n",
    "\n",
    "        # add angles to data set\t    \t\n",
    "        steering_angles.extend([steering_center, steering_left, steering_right])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flipping images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "augmented_images, augmented_measurements = [], []\n",
    "for image, measurement in zip(car_images, steering_angles):\n",
    "    augmented_images.append(image)\n",
    "    augmented_measurements.append(measurement)\n",
    "\n",
    "    augmented_images.append(cv2.flip(image, 1))\n",
    "    augmented_measurements.append(measurement * -1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.array(augmented_images)\n",
    "y_train = np.array(augmented_measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leNet(X_train, y_train):\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "    model.add(Cropping2D(cropping=((70, 25), (0, 0))))\n",
    "    model.add(Conv2D(6, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(6, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(120))\n",
    "    model.add(Dense(84))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=5)\n",
    "\n",
    "    model.save('model_lenet.h5')\n",
    "    print(\"Model saved as model_lenet.h5\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13195 samples, validate on 3299 samples\n",
      "Epoch 1/5\n",
      "13195/13195 [==============================] - 24s 2ms/step - loss: 0.1742 - val_loss: 0.1045\n",
      "Epoch 2/5\n",
      "13195/13195 [==============================] - 24s 2ms/step - loss: 0.0632 - val_loss: 0.0941\n",
      "Epoch 3/5\n",
      "13195/13195 [==============================] - 24s 2ms/step - loss: 0.0585 - val_loss: 0.0930\n",
      "Epoch 4/5\n",
      "13195/13195 [==============================] - 24s 2ms/step - loss: 0.0555 - val_loss: 0.0892\n",
      "Epoch 5/5\n",
      "13195/13195 [==============================] - 24s 2ms/step - loss: 0.0528 - val_loss: 0.0902\n",
      "Model saved as model_lenet.h5\n"
     ]
    }
   ],
   "source": [
    "leNet(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NVidia CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-729da1d6da65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "img_shape = X_train[0].shape\n",
    "print(img_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all of these pixels contain useful information, however. In the image above, the top portion of the image captures trees and hills and sky, and the bottom portion of the image captures the hood of the car.\n",
    "\n",
    "Your model might train faster if you crop each image to focus on only the portion of the image that is useful for predicting a steering angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Nvidia_CNN(X_train, y_train, input_shape=(160, 320, 3)):\n",
    "    model = Sequential()\n",
    "    # Preprocess incoming data, centered around zero with small standard deviation \n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "             input_shape=input_shape))\n",
    "    # crop images \n",
    "#     model.add(Cropping2D(cropping=((70, 25), (0, 0))))\n",
    "    \n",
    "    # adding 5 convolutions \n",
    "    model.add(Conv2D(24, (5, 5), strides=(2, 2), padding='valid', kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(Conv2D(36, (5, 5), strides=(2, 2), padding='valid', kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(Conv2D(48, (5, 5), strides=(2, 2), padding='valid', kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='valid', kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='valid', kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='valid', kernel_initializer='he_normal', activation='relu'))\n",
    "    \n",
    "    # Fully connected layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1164, kernel_initializer='he_normal'))\n",
    "    model.add(Dense(100, kernel_initializer='he_normal'))\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(Dense(10, kernel_initializer='he_normal'))\n",
    "    model.add(Dense(1, kernel_initializer='he_normal'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=5)\n",
    "\n",
    "    model.save('model_nvidia.h5')\n",
    "    print(\"Model saved as model_nvidia.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13195 samples, validate on 3299 samples\n",
      "Epoch 1/5\n",
      "13195/13195 [==============================] - 84s 6ms/step - loss: 44.2006 - val_loss: 0.1140\n",
      "Epoch 2/5\n",
      "13195/13195 [==============================] - 82s 6ms/step - loss: 0.0705 - val_loss: 0.1140\n",
      "Epoch 3/5\n",
      "13195/13195 [==============================] - 82s 6ms/step - loss: 0.0677 - val_loss: 0.0982\n",
      "Epoch 4/5\n",
      "13195/13195 [==============================] - 82s 6ms/step - loss: 0.0676 - val_loss: 0.0958\n",
      "Epoch 5/5\n",
      "13195/13195 [==============================] - 82s 6ms/step - loss: 0.0659 - val_loss: 0.0990\n",
      "Model saved as model_nvidia.h5\n"
     ]
    }
   ],
   "source": [
    "Nvidia_CNN(X_train, y_train, input_shape=img_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = []\n",
    "with open(\"../data-car-behavioral/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: #loop forever so the generator never terminates\n",
    "        sklearn.utils.shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset: offset + batch_size]\n",
    "            \n",
    "            car_images = []\n",
    "            steering_angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                steering_center = float(batch_sample[3])\n",
    "                \n",
    "                # create adjusted steering angles for the 2 side camera images (left and right one)\n",
    "                correction = steering_center * 0.1 #10%\n",
    "                steering_left = steering_center + correction\n",
    "                steering_right = steering_center - correction\n",
    "                \n",
    "                # read in images from center, left and right cameras\n",
    "                for i in range(3):\n",
    "                    source_path = batch_sample[i]\n",
    "                    filename = source_path.split('/')[-1]\n",
    "                    current_path = '../data-car-behavioral/IMG/' + filename\n",
    "                    image = cv2.imread(current_path)                    \n",
    "                    car_images.append(image)\n",
    "                    \n",
    "                steering_angles.extend([steering_center, steering_left, steering_right])\n",
    "            \n",
    "            X_train = np.array(car_images)\n",
    "            y_train = np.array(steering_angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "train_generator = generator(train_samples, batch_size=BATCH_SIZE)\n",
    "validation_generator = generator(validation_samples, batch_size=BATCH_SIZE)\n",
    "\n",
    "row, col, ch = 160, 320, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Nvidia_CNN_gen(train_generator, samples_per_epoch, validation_generator, \n",
    "                   num_val_samples, input_shape=(160, 320, 3)):\n",
    "    model = Sequential()\n",
    "    # Preprocess incoming data, centered around zero with small standard deviation \n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "             input_shape=input_shape))\n",
    "    # crop images \n",
    "#     model.add(Cropping2D(cropping=((70, 25), (0, 0))))\n",
    "    \n",
    "    # adding 5 convolutions \n",
    "    model.add(Conv2D(24, (5, 5), strides=(2, 2), padding='valid', kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(Conv2D(36, (5, 5), strides=(2, 2), padding='valid', kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(Conv2D(48, (5, 5), strides=(2, 2), padding='valid', kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='valid', kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='valid', kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='valid', kernel_initializer='he_normal', activation='relu'))\n",
    "    \n",
    "    # Fully connected layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1164, kernel_initializer='he_normal'))\n",
    "    model.add(Dense(100, kernel_initializer='he_normal'))\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(Dense(10, kernel_initializer='he_normal'))\n",
    "    model.add(Dense(1, kernel_initializer='he_normal'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    history_object = model.fit_generator(train_generator, steps_per_epoch=samples_per_epoch,\n",
    "                        epochs=5,\n",
    "                        validation_data=validation_generator, validation_steps=num_val_samples)\n",
    "\n",
    "    model.save('model_nvidia_gen.h5')\n",
    "    print(\"Model saved as model_nvidia_gen.h5\")\n",
    "    return history_object.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "history = Nvidia_CNN_gen(train_generator, len(train_samples), validation_generator, len(validation_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
